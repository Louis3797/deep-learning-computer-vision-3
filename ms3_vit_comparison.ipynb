{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate evaluate scikit-learn matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForImageClassification,\n",
    "    AutoImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results/ms3\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/models\", exist_ok=True)\n",
    "print(f\"Results will be saved to {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb292fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"deit_base\": {\n",
    "        \"model_name\": \"facebook/deit-base-patch16-224\",\n",
    "    },\n",
    "    \"deit_small\": {\n",
    "        \"model_name\": \"facebook/deit-small-patch16-224\",\n",
    "    },\n",
    "    \"swin_base\": {\n",
    "        \"model_name\": \"microsoft/swin-base-patch4-window7-224\",\n",
    "    },\n",
    "    \"beit_base\": {\n",
    "        \"model_name\": \"microsoft/beit-base-patch16-224\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Models for comparison:\")\n",
    "for name, config in MODELS.items():\n",
    "    print(f\"  - {name}: {config['model_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184da730",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c65abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cifar10\")\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "\n",
    "print(f\"Classes: {labels}\")\n",
    "print(f\"Training images: {len(dataset['train'])}\")\n",
    "print(f\"Test images: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995a391",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationConfig:\n",
    "    def __init__(self):\n",
    "        self.use_cutmix = True\n",
    "        self.use_mixup = True\n",
    "        self.cutmix_prob = 0.4\n",
    "        self.mixup_prob = 0.2\n",
    "        self.cutmix_alpha = 0.8\n",
    "        self.mixup_alpha = 0.6\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix_data(images, labels, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = images.size(0)\n",
    "    index = torch.randperm(batch_size).to(images.device)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "    images[:, :, bbx1:bbx2, bby1:bby2] = images[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
    "    return images, labels, labels[index], lam\n",
    "\n",
    "\n",
    "def mixup_data(images, labels, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = images.size(0)\n",
    "    index = torch.randperm(batch_size).to(images.device)\n",
    "    mixed_images = lam * images + (1 - lam) * images[index]\n",
    "    return mixed_images, labels, labels[index], lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "aug_config = AugmentationConfig()\n",
    "train_transforms = get_train_transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b7105",
   "metadata": {},
   "source": [
    "## Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811622a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedTrainer(Trainer):\n",
    "    def __init__(self, *args, aug_config=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.aug_config = aug_config or AugmentationConfig()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "\n",
    "        if self.model.training:\n",
    "            r = np.random.rand()\n",
    "            if self.aug_config.use_cutmix and r < self.aug_config.cutmix_prob:\n",
    "                inputs[\"pixel_values\"], labels_a, labels_b, lam = cutmix_data(\n",
    "                    inputs[\"pixel_values\"], labels, self.aug_config.cutmix_alpha\n",
    "                )\n",
    "                outputs = model(**inputs)\n",
    "                loss = mixup_criterion(nn.CrossEntropyLoss(), outputs.logits, labels_a, labels_b, lam)\n",
    "            elif self.aug_config.use_mixup and r < (self.aug_config.cutmix_prob + self.aug_config.mixup_prob):\n",
    "                inputs[\"pixel_values\"], labels_a, labels_b, lam = mixup_data(\n",
    "                    inputs[\"pixel_values\"], labels, self.aug_config.mixup_alpha\n",
    "                )\n",
    "                outputs = model(**inputs)\n",
    "                loss = mixup_criterion(nn.CrossEntropyLoss(), outputs.logits, labels_a, labels_b, lam)\n",
    "            else:\n",
    "                outputs = model(**inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "        else:\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89341770",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"macro\")\n",
    "    \n",
    "    precision, recall, _, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "        \"f1_macro\": f1[\"f1\"],\n",
    "        \"precision_macro\": precision,\n",
    "        \"recall_macro\": recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741abd9",
   "metadata": {},
   "source": [
    "## CSV Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_history(trainer, model_key):\n",
    "    history = trainer.state.log_history\n",
    "    \n",
    "    train_data = []\n",
    "    eval_data = []\n",
    "    \n",
    "    for entry in history:\n",
    "        if \"loss\" in entry and \"eval_loss\" not in entry:\n",
    "            train_data.append({\n",
    "                \"step\": entry.get(\"step\", 0),\n",
    "                \"epoch\": entry.get(\"epoch\", 0),\n",
    "                \"loss\": entry.get(\"loss\", 0),\n",
    "                \"learning_rate\": entry.get(\"learning_rate\", 0),\n",
    "            })\n",
    "        if \"eval_loss\" in entry:\n",
    "            eval_data.append({\n",
    "                \"step\": entry.get(\"step\", 0),\n",
    "                \"epoch\": entry.get(\"epoch\", 0),\n",
    "                \"eval_loss\": entry.get(\"eval_loss\", 0),\n",
    "                \"eval_accuracy\": entry.get(\"eval_accuracy\", 0),\n",
    "                \"eval_f1_macro\": entry.get(\"eval_f1_macro\", 0),\n",
    "            })\n",
    "    \n",
    "    if train_data:\n",
    "        df_train = pd.DataFrame(train_data)\n",
    "        df_train.to_csv(f\"{RESULTS_DIR}/{model_key}_training_history.csv\", index=False)\n",
    "    \n",
    "    if eval_data:\n",
    "        df_eval = pd.DataFrame(eval_data)\n",
    "        df_eval.to_csv(f\"{RESULTS_DIR}/{model_key}_eval_history.csv\", index=False)\n",
    "\n",
    "\n",
    "def save_classification_report(y_true, y_pred, model_key, label_names):\n",
    "    report = classification_report(y_true, y_pred, target_names=label_names, output_dict=True)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    df_report.to_csv(f\"{RESULTS_DIR}/{model_key}_classification_report.csv\")\n",
    "    return report\n",
    "\n",
    "\n",
    "def save_confusion_matrix(y_true, y_pred, model_key, label_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=label_names, columns=label_names)\n",
    "    df_cm.to_csv(f\"{RESULTS_DIR}/{model_key}_confusion_matrix.csv\")\n",
    "    return cm\n",
    "\n",
    "\n",
    "def save_per_class_metrics(y_true, y_pred, model_key, label_names):\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"class\": label_names,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"support\": support.astype(int),\n",
    "    })\n",
    "    df_metrics.to_csv(f\"{RESULTS_DIR}/{model_key}_per_class_metrics.csv\", index=False)\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "def save_overall_metrics(metrics_dict, model_key):\n",
    "    df = pd.DataFrame([metrics_dict])\n",
    "    df.to_csv(f\"{RESULTS_DIR}/{model_key}_overall_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba3c36",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.1\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "\n",
    "\n",
    "def train_model(model_key, model_config):\n",
    "    \n",
    "    model_name = model_config[\"model_name\"]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_key}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    \n",
    "    def preprocess_train(examples):\n",
    "        images = []\n",
    "        for img in examples[\"img\"]:\n",
    "            img = img.convert(\"RGB\")\n",
    "            if train_transforms:\n",
    "                img = train_transforms(img)\n",
    "            images.append(img)\n",
    "        inputs = processor(images, return_tensors=\"pt\")\n",
    "        inputs[\"labels\"] = examples[\"label\"]\n",
    "        return inputs\n",
    "\n",
    "    def preprocess_val(examples):\n",
    "        images = [img.convert(\"RGB\") for img in examples[\"img\"]]\n",
    "        inputs = processor(images, return_tensors=\"pt\")\n",
    "        inputs[\"labels\"] = examples[\"label\"]\n",
    "        return inputs\n",
    "\n",
    "    train_ds = dataset[\"train\"].with_transform(preprocess_train)\n",
    "    val_ds = dataset[\"test\"].with_transform(preprocess_val)\n",
    "    \n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        id2label={str(i): label for i, label in enumerate(labels)},\n",
    "        label2id={label: str(i) for i, label in enumerate(labels)}\n",
    "    )\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Parameters: {total_params:,} (trainable: {trainable_params:,})\")\n",
    "    \n",
    "    output_dir = f\"{RESULTS_DIR}/models/{model_key}\"\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        seed=42,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        dataloader_num_workers=2,\n",
    "    )\n",
    "    \n",
    "    trainer = AugmentedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE)],\n",
    "        aug_config=aug_config\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_result = trainer.train()\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Training completed in {training_time/60:.1f} minutes\")\n",
    "    \n",
    "    eval_result = trainer.evaluate()\n",
    "    print(f\"Test Accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
    "    print(f\"Test Loss: {eval_result['eval_loss']:.4f}\")\n",
    "    \n",
    "    predictions = trainer.predict(val_ds)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "    y_true = predictions.label_ids\n",
    "    \n",
    "    save_training_history(trainer, model_key)\n",
    "    save_classification_report(y_true, y_pred, model_key, labels)\n",
    "    save_confusion_matrix(y_true, y_pred, model_key, labels)\n",
    "    df_perclass = save_per_class_metrics(y_true, y_pred, model_key, labels)\n",
    "    \n",
    "    overall = {\n",
    "        \"model\": model_key,\n",
    "        \"accuracy\": eval_result[\"eval_accuracy\"],\n",
    "        \"f1_macro\": eval_result[\"eval_f1_macro\"],\n",
    "        \"precision_macro\": eval_result[\"eval_precision_macro\"],\n",
    "        \"recall_macro\": eval_result[\"eval_recall_macro\"],\n",
    "        \"test_loss\": eval_result[\"eval_loss\"],\n",
    "        \"train_loss\": train_result.metrics.get(\"train_loss\", 0),\n",
    "        \"epochs_trained\": len([l for l in trainer.state.log_history if \"eval_loss\" in l]),\n",
    "        \"training_time_min\": training_time / 60,\n",
    "        \"total_params\": total_params,\n",
    "        \"architecture\": model_config.get(\"description\", model_name),\n",
    "    }\n",
    "    save_overall_metrics(overall, model_key)\n",
    "    \n",
    "    trainer.save_model(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "    \n",
    "    print(f\"CSVs saved for {model_key}\")\n",
    "    \n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return overall, df_perclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67f6e1",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "all_perclass = {}\n",
    "\n",
    "for i, (model_key, model_config) in enumerate(MODELS.items(), 1):\n",
    "    print(f\"\\n[{i}/{len(MODELS)}] {model_key}\")\n",
    "    \n",
    "    try:\n",
    "        overall, perclass = train_model(model_key, model_config)\n",
    "        all_results.append(overall)\n",
    "        all_perclass[model_key] = perclass\n",
    "        \n",
    "        df_all = pd.DataFrame(all_results)\n",
    "        df_all.to_csv(f\"{RESULTS_DIR}/all_models_comparison.csv\", index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_key}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c24a6",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63945ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_ms2_results = [\n",
    "    {\n",
    "        \"model\": \"vit_base_ms1\",\n",
    "        \"accuracy\": 0.9896,\n",
    "        \"f1_macro\": 0.9896,\n",
    "        \"test_loss\": 0.0436,\n",
    "        \"train_loss\": 0.6220,\n",
    "        \"epochs_trained\": 21,\n",
    "        \"total_params\": 85800000,\n",
    "        \"architecture\": \"ViT Baseline (MS1)\",\n",
    "        \"source\": \"MS1\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"hybrid_vit_ms2\",\n",
    "        \"accuracy\": 0.9870,\n",
    "        \"f1_macro\": 0.9870,\n",
    "        \"test_loss\": 0.0528,\n",
    "        \"train_loss\": 0.6238,\n",
    "        \"epochs_trained\": 14,\n",
    "        \"total_params\": 118300000,\n",
    "        \"architecture\": \"Hybrid ViT (MS2)\",\n",
    "        \"source\": \"MS2\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"resnet50_ms1\",\n",
    "        \"accuracy\": 0.9750,\n",
    "        \"f1_macro\": 0.9750,\n",
    "        \"test_loss\": 0.0862,\n",
    "        \"train_loss\": 0.6887,\n",
    "        \"epochs_trained\": 49,\n",
    "        \"total_params\": 23500000,\n",
    "        \"architecture\": \"ResNet-50 (MS1)\",\n",
    "        \"source\": \"MS1\"\n",
    "    }\n",
    "]\n",
    "\n",
    "df_ms1_ms2 = pd.DataFrame(ms1_ms2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ms3 = pd.read_csv(f\"{RESULTS_DIR}/all_models_comparison.csv\")\n",
    "df_ms3[\"source\"] = \"MS3\"\n",
    "\n",
    "df_all = pd.concat([df_ms3, df_ms1_ms2], ignore_index=True)\n",
    "df_all = df_all.sort_values(\"accuracy\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Complete comparison of all models:\")\n",
    "print(df_all[[\"model\", \"accuracy\", \"f1_macro\", \"test_loss\", \"total_params\", \"source\"]].to_string())\n",
    "\n",
    "df_all.to_csv(f\"{RESULTS_DIR}/complete_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "colors = [\"tab:blue\" if s == \"MS3\" else \"tab:orange\" if s == \"MS2\" else \"tab:green\" for s in df_all[\"source\"]]\n",
    "ax1.barh(df_all[\"model\"], df_all[\"accuracy\"], color=colors)\n",
    "ax1.set_xlabel(\"Accuracy\")\n",
    "ax1.set_title(\"Accuracy Comparison\")\n",
    "ax1.set_xlim([0.97, 1.0])\n",
    "\n",
    "ax2 = axes[1]\n",
    "for source, color in [(\"MS1\", \"tab:green\"), (\"MS2\", \"tab:orange\"), (\"MS3\", \"tab:blue\")]:\n",
    "    mask = df_all[\"source\"] == source\n",
    "    ax2.scatter(\n",
    "        df_all[mask][\"total_params\"] / 1e6,\n",
    "        df_all[mask][\"accuracy\"],\n",
    "        c=color,\n",
    "        s=100,\n",
    "        label=source,\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "ax2.set_xlabel(\"Parameters (millions)\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_title(\"Accuracy vs Model Size\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/comparison_plots.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e897a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_perclass:\n",
    "    perclass_data = []\n",
    "    for model_key, df in all_perclass.items():\n",
    "        for _, row in df.iterrows():\n",
    "            perclass_data.append({\n",
    "                \"model\": model_key,\n",
    "                \"class\": row[\"class\"],\n",
    "                \"f1\": row[\"f1_score\"]\n",
    "            })\n",
    "    \n",
    "    df_perclass_all = pd.DataFrame(perclass_data)\n",
    "    pivot = df_perclass_all.pivot(index=\"class\", columns=\"model\", values=\"f1\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".3f\", cmap=\"RdYlGn\", vmin=0.95, vmax=1.0)\n",
    "    plt.title(\"F1-Score per Class (MS3 Models)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/perclass_heatmap.png\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saved files:\\n\")\n",
    "for f in sorted(os.listdir(RESULTS_DIR)):\n",
    "    if f.endswith(\".csv\") or f.endswith(\".png\"):\n",
    "        print(f\"  {f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
